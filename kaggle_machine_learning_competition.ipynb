{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pete Schultz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a text classification task. Every document (a line in the data file) is a movie review from IMDB. Your goal is to classify each document into ONE of the two categories, based on whether it needs simplification: 1 if the review is positive; 0 if the review is negative.\n",
    "\n",
    "The training data contains 10,000 reviews, already labeled with one of the above categories. The test data contains 5,000 reviews that are unlabeled. The submission should be a .csv (comma separated free text) file with a header line ”Id,Category” followed by exactly 5,000 lines. In each line, there should be exactly two integers, separated by a comma. The first integer is the line ID of a test question (0 - 5,000), and the second integer is the category your classifier predicts one of (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram\n",
    "unigram_vect = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vect.fit(train.text)\n",
    "\n",
    "X_train_unigram = unigram_vect.transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram\n",
    "bigram_vect = CountVectorizer(ngram_range=(1, 2))\n",
    "bigram_vect.fit(train.text)\n",
    "\n",
    "X_train_bigram = bigram_vect.transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram\n",
    "trigram_vect = CountVectorizer(ngram_range=(1, 3))\n",
    "trigram_vect.fit(train.text)\n",
    "\n",
    "X_train_trigram = trigram_vect.transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrigram\n",
    "quadrigram_vect = CountVectorizer(ngram_range=(1, 4))\n",
    "quadrigram_vect.fit(train.text)\n",
    "\n",
    "X_train_quadrigram = quadrigram_vect.transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram tf idf\n",
    "unigram_tf_idf_trans = TfidfTransformer()\n",
    "unigram_tf_idf_trans.fit(X_train_unigram)\n",
    "\n",
    "X_train_unigram_tf_idf = unigram_tf_idf_trans.transform(X_train_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram tf idf\n",
    "bigram_tf_idf_trans = TfidfTransformer()\n",
    "bigram_tf_idf_trans.fit(X_train_bigram)\n",
    "\n",
    "X_train_bigram_tf_idf = bigram_tf_idf_trans.transform(X_train_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram tf idf\n",
    "trigram_tf_idf_trans = TfidfTransformer()\n",
    "trigram_tf_idf_trans.fit(X_train_trigram)\n",
    "\n",
    "X_train_trigram_tf_idf = trigram_tf_idf_trans.transform(X_train_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrigram tf idf\n",
    "quadrigram_tf_idf_trans = TfidfTransformer()\n",
    "quadrigram_tf_idf_trans.fit(X_train_quadrigram)\n",
    "\n",
    "X_train_quadrigram_tf_idf = quadrigram_tf_idf_trans.transform(X_train_quadrigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(kind, X, y):\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 142)\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(f'{kind}\\n')\n",
    "    print(f'Train score: {round(train_score, 2)}\\nTest score: {round(test_score, 3)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.838\n",
      "\n",
      "Bigram\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.856\n",
      "\n",
      "Trigram\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.854\n",
      "\n",
      "Quadrigram\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.846\n",
      "\n",
      "Unigram Tf-Idf\n",
      "\n",
      "Train score: 0.98\n",
      "Test score: 0.87\n",
      "\n",
      "Bigram Tf-Idf\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.886\n",
      "\n",
      "Trigram Tf-Idf\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.88\n",
      "\n",
      "Quadrigram Tf-Idf\n",
      "\n",
      "Train score: 1.0\n",
      "Test score: 0.873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calc_scores('Unigram', X_train_unigram, y_train)\n",
    "calc_scores('Bigram', X_train_bigram, y_train)\n",
    "calc_scores('Trigram', X_train_trigram, y_train)\n",
    "calc_scores('Quadrigram', X_train_quadrigram, y_train)\n",
    "calc_scores('Unigram Tf-Idf', X_train_unigram_tf_idf, y_train)\n",
    "calc_scores('Bigram Tf-Idf', X_train_bigram_tf_idf, y_train)\n",
    "calc_scores('Trigram Tf-Idf', X_train_trigram_tf_idf, y_train)\n",
    "calc_scores('Quadrigram Tf-Idf', X_train_quadrigram_tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: Bigram Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bigram = bigram_vect.transform(test.text)\n",
    "X_test_bigram_tf_idf = bigram_tf_idf_trans.transform(X_test_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier()\n",
    "clf.fit(X_train_bigram_tf_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_bigram_tf_idf)\n",
    "pd.DataFrame({\"Id\": test.Id, \"Category\": predictions}).to_csv(\"pete_kaggle.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
